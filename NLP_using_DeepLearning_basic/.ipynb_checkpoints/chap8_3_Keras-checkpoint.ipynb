{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥 러닝을 이용한 자연어 처리 입문\n",
    "\n",
    "https://wikidocs.net/22660"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 08. NLP를 위한 딥 러닝 개요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 08-3 Keras 훑어보기\n",
    "\n",
    "손쉽게 딥러닝을 구현할 수 있도록 하는 상위 레벨 interface\n",
    "\n",
    "참고 : https://keras.io/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 전처리(Preprocessing)\n",
    "\n",
    "    Tokenizer(): 토큰화와 정수 인코딩에 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequences :  [1, 2, 3, 4, 6, 7] \n",
      "\n",
      "word index :  {'the': 1, 'earth': 2, 'is': 3, 'an': 4, 'awsome': 5, 'place': 6, 'live': 7, 'rabbits': 8, 'lives': 9, 'in': 10, 'moon': 11}\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "t = Tokenizer()\n",
    "\n",
    "fit_text= \"The earth is an awsome place live\"\n",
    "fit_text2= \"Rabbits lives in the Moon\"\n",
    "\n",
    "# 여러 문장의 토큰화 된 단어를 기준으로 단어집합을 만든다.\n",
    "t.fit_on_texts([fit_text,fit_text2])\n",
    "\n",
    "test_text = \"The earth is an great place live\"\n",
    "\n",
    "# 만들어진 단어집합의 인덱스를 참고하여 해당 단어의 인덱스 출력\n",
    "sequences = t.texts_to_sequences([test_text])[0]\n",
    "\n",
    "print('sequences : ', sequences, '\\n') # great는 단어집합에 없으므로 출력 X\n",
    "print('word index : ', t.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    pad_sequence([각 문장의 토큰 리스트], maxlen = ) : 모델의 입력으로 사용 시 길이를 맞추어야 한다.\n",
    "    \n",
    "정해준 길이에 대해 모든 데이터를 같은 길이로 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6],\n",
       "       [0, 7, 8]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# 짧은 것은 0으로 채워 padding해준다.\n",
    "# 긴 것은 뒷부분을 선택해준다.\n",
    "\n",
    "# 정수 인코딩이 끝났다고 가정하고 실행\n",
    "pad_sequences([[1,2,3],[3,4,5,6],[7,8]], maxlen = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 워드 임베딩(Word Embedding)\n",
    "\n",
    "기계가 텍스트를 숫자로 인식할 수 있도록 밀집벡터(Dense Vector)로 만들어주는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Embedding(단어 집합의 크기, 임베딩 된 출력 벡터 차원, input_length = 입력 시퀀스의 길이) : 밀집벡터로 만드는 역할\n",
    "    \n",
    "신경망 구조적 관점에서 임베딩 층(Embedding layer) 를 만든다.\n",
    "\n",
    "정수로 인코딩 된 벡터를 임베딩 벡터로 만들어준다.\n",
    "\n",
    "단어의 의미(semantics)까지 벡터화하지는 못하지만,\n",
    "\n",
    "입력 벡터로 사용하기 위해 빠르게 밀집 벡터 형태로 만들어줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary set : {'to': 1, 'see': 2, 'you': 3, 'hope': 4, 'soon': 5, 'nice': 6, 'again': 7}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.layers.embeddings.Embedding at 0x1289cf8a358>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=[['Hope', 'to', 'see', 'you', 'soon'],['Nice', 'to', 'see', 'you', 'again']]\n",
    "\n",
    "text_tok = Tokenizer()\n",
    "text_tok.fit_on_texts(text)\n",
    "\n",
    "print('vocabulary set :', text_tok.word_index)\n",
    "# 정수 인코딩 된 벡터\n",
    "text_tok_encode = text_tok.texts_to_sequences(text)\n",
    "\n",
    "\n",
    "# 워드 임베딩 실행\n",
    "# Embedding(단어 집합 크기, 임베딩할 벡터 길이, input 벡터 길이)\n",
    "Embedding(len(text_tok.word_index), 2, input_length = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 모델링(Modeling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Sequential() : 층을 구성하는 함수\n",
    "    \n",
    "    Sequential객체.add(층) : 해당 모델에 층을 추가한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(text_tok.word_index), 2, input_length = 5))# embedding층을 추가한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Dense() : 일반적인 층을 만드는 함수, 인자(몇개의 node, 활성화 함수 등등..)\n",
    "    \n",
    "인자\n",
    "- 첫번째 : 출력 노드 수\n",
    "- input_dim : 입력 노드 수\n",
    "- init : 가중치 초기화 방법\n",
    "- activation : 활성화 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, input_dim=3, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim = 3, init = 'uniform', activation ='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, input_dim=4, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim = 4, init = 'uniform', activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "# 첫번째 층 이후에 다음 층 추가\n",
    "# 즉, 첫번째 층은 더이상, 출력층이 아니다\n",
    "\n",
    "# 두번째 층 Dense 함수에서 input_dim 선언을 하지 않아도 된다.\n",
    "## 그 이전층에서 출력 node의 수로 dimension 을 알 수 있기 때문"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 컴파일(Compile)과 훈련(Training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    compile() : 모델링한 모델을 컴퓨터가 이해할 수 있도록\n",
    "\n",
    "인자\n",
    "- 오차함수\n",
    "- 최적화 방법\n",
    "- 모델 수행 결과를 매트릭스 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import SimpleRNN, Embedding, Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "max_features = 10000\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 32)) # 32차원으로 word embedding\n",
    "model.add(SimpleRNN(32))\n",
    "model.add(Dense(1, activation = 'sigmoid')) # 출력층 노드는 1개, 즉 출력값 1개\n",
    "\n",
    "#컴파일\n",
    "model.compile(optimizer = 'rmsprop', loss='binary_crossentropy', metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    fit() : 모델을 실제로 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
