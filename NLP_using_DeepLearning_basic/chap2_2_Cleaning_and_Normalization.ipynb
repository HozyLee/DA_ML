{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥 러닝을 이용한 자연어 처리 입문\n",
    "\n",
    "https://wikidocs.net/22660"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02. 텍스트 전처리(text preprocessing)\n",
    "\n",
    "분석에 앞서 텍스트를 사전에 분류하는 작업"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02-2 정제(Cleaning) 과 정규화(Normalization)\n",
    "\n",
    "\n",
    "주로 토큰화 작업 전 수행, 필요하다면 토큰화 이후에도 지속적으로 수행\n",
    "    \n",
    "    정제(Cleaning) : 갖고 있는 코퍼스로부터 노이즈 제거\n",
    "    정규화(Normalization) : 포현 방법이 다른 단어들을 통합시켜 같은 단어로 만든다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 규칙에 기반한 표기가 다른 단어들의 통합\n",
    "\n",
    "ex) US = USA, un-huh = uhhuh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 대,소문자 통합\n",
    "\n",
    "검색엔진에서 대,소문자가 달라도 같은 문자로 인식한다.\n",
    "\n",
    "통합하면 안되는 경우\n",
    "    \n",
    "    회사 이름\n",
    "    사람 이름\n",
    "    \n",
    "    \n",
    "대안 제시\n",
    "\n",
    "문장의 맨 앞의 단어만 소문자로 변환한 후 나머지는 남겨두는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 불필요한 단어의 제거(Removing Unnecessary Words)\n",
    "\n",
    "노이즈 데이터\n",
    "    \n",
    "    자연어가 아니면서 아무 의미도 갖지 않는 글자(특수 문자)\n",
    "    분석하고자 하는 목적에 부합하지 않는 단어들\n",
    "    \n",
    "불필요한 단어 제거 방법\n",
    "\n",
    "    1. 불용어 제거\n",
    "    2. 등장빈도가 적은 단어 제거\n",
    "    3. 길이가 짧은 단어 제거"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1) 등장 빈도가 적은 단어 제거(Removing Rare words)\n",
    "\n",
    "등장 빈도가 적어 분석에 큰 의미를 주지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (2) 길이가 짧은 단어(Removing words with very a short length)\n",
    "\n",
    "영어권 : 길이가 짧은 단어의 경우 주로 불용어이다. 따라서, 꽤 괜찮은 효과를 본다.\n",
    "\n",
    "한국어 : 꼭 그렇지만은 않다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " was wondering anyone out there could enlighten this car.\n"
     ]
    }
   ],
   "source": [
    "# 길이가 1~1 인 단어들을 정규표현식을 이용하여 삭제\n",
    "import re\n",
    "\n",
    "text = \"I was wondering if anyone out there could enlighten me on this car.\"\n",
    "\n",
    "shortword  = re.compile(r'\\W*\\b\\w{1,2}\\b')\n",
    "\n",
    "print(shortword.sub('', text))\n",
    "\n",
    "# I가 걸러졌다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 정규표현식\n",
    "\n",
    "노이즈 데이터의 특징을 어느정도 알고 있는 경우 정규표현식 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
